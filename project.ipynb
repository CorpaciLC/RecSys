{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b5ecc5d390fe3fdcc1d7048181fbcbb",
     "grade": false,
     "grade_id": "cell-3a49d0c736ae4826",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Project\n",
    "\n",
    "Welcome to the group project! The project is based on the [ACM RecSys 2021 Challenge](https://recsys-twitter.com/).\n",
    "\n",
    "- Detailed information about the task, submission and grading can be found in a [dedicates site on TUWEL](https://tuwel.tuwien.ac.at/mod/page/view.php?id=1217340).\n",
    "- Information about the dataset structure [on this site on TUWEL](https://tuwel.tuwien.ac.at/mod/page/view.php?id=1218810)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"team_15\" # your team name e.g. 'team_1'\n",
    "team_members = [(\"Markus Böck\",\"01634838\"),\n",
    "                (\"Luiza Corpaci\",\"12037284\"),\n",
    "                (\"Iulia Cristina Hatiegan\", \"01302969\"),\n",
    "                (\"Adriana-Maria Railean\", \"01304039\"),\n",
    "                (\"\", \"\")] # [(\"Jane Doe\",\"012345678\"), (\"John Doe\",\"012345678\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c84ed38479c0195aaa2fa1ce3f7fece",
     "grade": false,
     "grade_id": "cell-07ef37bf8c0d782b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team_15\n",
      "[('Markus Böck', '01634838'), ('Luiza Corpaci', '12037284'), ('Iulia Cristina Hatiegan', '01302969'), ('Adriana-Maria Railean', '01304039'), ('', '')]\n"
     ]
    }
   ],
   "source": [
    "print(team_name)\n",
    "print(team_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = './data/project/training/'\n",
    "val_path_to_data = './data/project/validation/'\n",
    "dataset_type = 'one_hour' # all_sorted, one_day, one_hour, one_week\n",
    "val_dataset_type = \"one_hour\"\n",
    "expanded_path = os.path.expanduser(path_to_data)\n",
    "part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "part_files = sorted(part_files, key = lambda x:x[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdcfa030c94d59246d7322f527c9ef7e",
     "grade": true,
     "grade_id": "cell-adf5f6bdd4704e08",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    if hasattr(sys, 'real_prefix'):\n",
    "        #we are in a virtual env.\n",
    "        !pip3 install pandas\n",
    "    else:\n",
    "        !pip3 install --user pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "from model import reply_pred_model, retweet_pred_model, quote_pred_model, fav_pred_model \n",
    "\n",
    "all_features =  [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                        \"tweet_type\",\"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "                       \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "                       \"engaging_user_id\", \"enaging_user_follower_count\", \"enaging_user_following_count\", \"enaging_user_is_verified\",\\\n",
    "                       \"enaging_user_account_creation\", \"engagee_follows_engager\", \"reply\", \"retweet\", \"quote\", \"like\"]\n",
    "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
    "\n",
    "def parse_input_line(line):\n",
    "    features = line #.split(\"\\x01\")\n",
    "    tweet_id = features[all_features_to_idx['tweet_id']]\n",
    "    user_id = features[all_features_to_idx['engaging_user_id']]\n",
    "    input_feats = features[all_features_to_idx['text_tokens']]\n",
    "    tweet_timestamp = features[all_features_to_idx['tweet_timestamp']]\n",
    "    \n",
    "    return tweet_id, user_id, input_feats, tweet_timestamp\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_test_set():\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "        \n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "                linereader = csv.reader(f, delimiter='\\x01')\n",
    "                last_timestamp = None\n",
    "                for row in linereader:\n",
    "                    tweet_id, user_id, features, tweet_timestamp = parse_input_line(row)                                       \n",
    "                    reply_pred = reply_pred_model(features) # reply_model\n",
    "                    retweet_pred = retweet_pred_model(features) # retweet_model\n",
    "                    quote_pred = quote_pred_model(features) # pred_model\n",
    "                    fav_pred = fav_pred_model(features) # fav_model\n",
    "                    \n",
    "                    # print(str(tweet_timestamp))\n",
    "                    # print(str(reply_pred)+\" \"+str(retweet_pred)+\" \"+str(quote_pred)+\" \"+str(fav_pred))\n",
    "                    \n",
    "                    output.write(f'{tweet_id},{user_id},{reply_pred},{retweet_pred},{quote_pred},{fav_pred}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "        data = pd.read_csv(filename, sep='\\x01', names=all_features, index_col=False)\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis & Baselines\n",
    "#### Author: Markus Böck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting statistics:\n",
    "- Number of rows\n",
    "- Numer of unique users\n",
    "- Number of unique tweets\n",
    "- Percentage of engagements (reply, retweet, quote, like)\n",
    "- Percentage of users of validation set appearing in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/project/training/one_hour.csv']\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res = {}\n",
    "for dataset_type in [\"one_hour\", \"one_day\", \"one_week\"]:\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:])\n",
    "    part_files\n",
    "    print(part_files)\n",
    "\n",
    "    tweet_counts = dict()\n",
    "    user_counts = dict()\n",
    "    \n",
    "    nreply = 0\n",
    "    nretweet = 0\n",
    "    nquote = 0\n",
    "    nlike = 0\n",
    "    nengagement = 0\n",
    "\n",
    "    nrows = 0\n",
    "    with open(part_files[0], 'r') as f:\n",
    "        linereader = csv.reader(f, delimiter='\\x01')\n",
    "        last_timestamp = None\n",
    "        i = 0\n",
    "        tik = time.time()\n",
    "        for row in linereader:\n",
    "            tweet_id = row[all_features_to_idx['tweet_id']]\n",
    "            user_id = row[all_features_to_idx['engaging_user_id']]\n",
    "            \n",
    "            reply = row[all_features_to_idx['reply']] != \"\"\n",
    "            retweet = row[all_features_to_idx['retweet']] != \"\"\n",
    "            quote = row[all_features_to_idx['quote']] != \"\"\n",
    "            like = row[all_features_to_idx['like']] != \"\"\n",
    "                \n",
    "            nreply += reply\n",
    "            nretweet += retweet\n",
    "            nquote += quote\n",
    "            nlike += like\n",
    "            nengagement += (reply or retweet or quote or like)\n",
    "                        \n",
    "            v = 0\n",
    "            try:\n",
    "                v = tweet_counts[tweet_id]\n",
    "            except:\n",
    "                pass\n",
    "            tweet_counts[tweet_id] = v + 1\n",
    "\n",
    "            v = 0\n",
    "            try:\n",
    "                v = user_counts[user_id]\n",
    "            except:\n",
    "                pass\n",
    "            user_counts[user_id] = v + 1\n",
    "\n",
    "            if i % 100000 == 0:\n",
    "                tok = time.time()\n",
    "                print(f\"{i} {100000/(tok-tik): .2f} iter/s\", end=\"\\r\")\n",
    "                tik = time.time()\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        nrows = i\n",
    "        \n",
    "        stats = {\"nrows\": nrows}\n",
    "        \n",
    "        stats[\"nreply\"] = nreply\n",
    "        stats[\"nretweet\"] = nretweet\n",
    "        stats[\"nquote\"] = nquote\n",
    "        stats[\"nlike\"] = nlike\n",
    "        stats[\"nengagement\"] = nengagement\n",
    "        \n",
    "        stats[\"unique_tweets\"] = len(tweet_counts)\n",
    "        stats[\"unique_users\"] = len(user_counts)\n",
    "        \n",
    "        percs = []\n",
    "        for i in range(1,11):\n",
    "            perc = sum([1 for (j,c) in tweet_counts.items() if c >= i])  / len(tweet_counts)\n",
    "            percs.append(perc)\n",
    "        stats[\"tweet_dist\"] = percs\n",
    "        \n",
    "        percs = []\n",
    "        for i in range(1,11):\n",
    "            perc = sum([1 for (j,c) in user_counts.items() if c >= i])  / len(user_counts)\n",
    "            percs.append(perc)\n",
    "        stats[\"user_dist\"] = percs\n",
    "        \n",
    "        stats[\"val_user_perc\"] = len(set(val_data[\"engaging_user_id\"].unique()).intersection(set(user_counts.keys()))) / val_data.shape[0] * 100\n",
    "        stats[\"val_tweet_perc\"] = len(set(val_data[\"tweet_id\"].unique()).intersection(set(tweet_counts.keys()))) / val_data.shape[0] * 100\n",
    "        \n",
    "        res[dataset_type] = stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data needs special treatment. Exploit the fact that this set is ordered according to tweet id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dataset_type = \"all_sorted\"\n",
    "expanded_path = os.path.expanduser(path_to_data)\n",
    "part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "part_files = sorted(part_files, key = lambda x:x[-5:])\n",
    "part_files\n",
    "print(part_files)\n",
    "\n",
    "current_tweet_id = \"\"\n",
    "tweet_count = 1\n",
    "tweet_dist = [0]*10\n",
    "n_unique_tweets = 0\n",
    "\n",
    "user_counts = dict()\n",
    "\n",
    "nreply = 0\n",
    "nretweet = 0\n",
    "nquote = 0\n",
    "nlike = 0\n",
    "nengagement = 0\n",
    "\n",
    "nrows = 0\n",
    "with open(part_files[0], 'r') as f:\n",
    "    linereader = csv.reader(f, delimiter='\\x01')\n",
    "    last_timestamp = None\n",
    "    i = 0\n",
    "    tik = time.time()\n",
    "    for row in linereader:\n",
    "        tweet_id = row[all_features_to_idx['tweet_id']]\n",
    "        user_id = row[all_features_to_idx['engaging_user_id']]\n",
    "\n",
    "        #print(tweet_id)\n",
    "        \n",
    "        if current_tweet_id == tweet_id:\n",
    "            tweet_count += 1\n",
    "        else:\n",
    "            #print(tweet_id, tweet_count)\n",
    "            for j in range(1, 11):\n",
    "                if tweet_count >= j:\n",
    "                    tweet_dist[j-1] += 1\n",
    "            tweet_count = 1\n",
    "            current_tweet_id = tweet_id\n",
    "            n_unique_tweets += 1\n",
    "                \n",
    "\n",
    "        reply = row[all_features_to_idx['reply']] != \"\"\n",
    "        retweet = row[all_features_to_idx['retweet']] != \"\"\n",
    "        quote = row[all_features_to_idx['quote']] != \"\"\n",
    "        like = row[all_features_to_idx['like']] != \"\"\n",
    "\n",
    "        nreply += reply\n",
    "        nretweet += retweet\n",
    "        nquote += quote\n",
    "        nlike += like\n",
    "        nengagement += (reply or retweet or quote or like)\n",
    "\n",
    "\n",
    "        v = 0\n",
    "        try:\n",
    "            v = user_counts[user_id]\n",
    "        except:\n",
    "            pass\n",
    "        user_counts[user_id] = v + 1\n",
    "\n",
    "        if i % 100000 == 0:\n",
    "            tok = time.time()\n",
    "            print(f\"{i} {100000/(tok-tik): .2f} iter/s\", end=\"\\r\")\n",
    "            tik = time.time()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    nrows = i\n",
    "\n",
    "    stats = {\"nrows\": nrows}\n",
    "\n",
    "    stats[\"nreply\"] = nreply\n",
    "    stats[\"nretweet\"] = nretweet\n",
    "    stats[\"nquote\"] = nquote\n",
    "    stats[\"nlike\"] = nlike\n",
    "    stats[\"nengagement\"] = nengagement\n",
    "\n",
    "    stats[\"unique_tweets\"] = n_unique_tweets\n",
    "    stats[\"unique_users\"] = len(user_counts)\n",
    "\n",
    "    stats[\"tweet_dist\"] = [d/n_unique_tweets for d in tweet_dist]\n",
    "\n",
    "    percs = []\n",
    "    for i in range(1,11):\n",
    "        perc = sum([1 for (j,c) in user_counts.items() if c >= i])  / len(user_counts)\n",
    "        percs.append(perc)\n",
    "    stats[\"user_dist\"] = percs\n",
    "\n",
    "    stats[\"val_user_perc\"] = len(set(val_data[\"engaging_user_id\"].unique()).intersection(set(user_counts.keys()))) / val_data.shape[0] * 100\n",
    "    stats[\"val_tweet_perc\"] = 0.\n",
    "\n",
    "res[dataset_type] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tweet_counts\n",
    "del user_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statistics\n",
    "for (k,stats) in res.items():\n",
    "    print(k)\n",
    "    print(\"\\tnrows\", stats[\"nrows\"])\n",
    "    \n",
    "    print(\"\\tnreply\", stats[\"nreply\"], \"-\", round(stats[\"nreply\"]/stats[\"nrows\"]*100,2), \"%\")\n",
    "    print(\"\\tnretweet\", stats[\"nretweet\"], \"-\", round(stats[\"nretweet\"]/stats[\"nrows\"]*100,2), \"%\")\n",
    "    print(\"\\tnquote\", stats[\"nquote\"], \"-\", round(stats[\"nquote\"]/stats[\"nrows\"]*100,2), \"%\")\n",
    "    print(\"\\tnlike\", stats[\"nlike\"], \"-\", round(stats[\"nlike\"]/stats[\"nrows\"]*100,2), \"%\")\n",
    "    print(\"\\tnengagement\", stats[\"nengagement\"], \"-\", round(stats[\"nengagement\"]/stats[\"nrows\"]*100,2), \"%\")\n",
    "          \n",
    "    print(\"\\tunique_tweets\", stats[\"unique_tweets\"])\n",
    "    print(\"\\tunique_users\", stats[\"unique_users\"])\n",
    "    print(\"\\tval_user_perc\", stats[\"val_user_perc\"])\n",
    "    try:\n",
    "        print(\"\\tval_tweet_perc\", stats[\"val_tweet_perc\"])\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for (k,stats) in res.items():\n",
    "    dist = stats[\"tweet_dist\"]\n",
    "    plt.plot(range(1,len(dist)+1), dist, label=k)\n",
    "    \n",
    "plt.legend()\n",
    "plt.title(\"% of tweets appearing more than n times\")\n",
    "plt.xlabel(\"n\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.savefig(\"tweets.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for (k,stats) in res.items():\n",
    "    dist = stats[\"user_dist\"]\n",
    "    plt.plot(range(1,len(dist)+1), dist, label=k)\n",
    "    \n",
    "plt.legend()\n",
    "plt.title(\"% of users appearing more than n times\")\n",
    "plt.xlabel(\"n\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.savefig(\"users.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_to_list(data, columns):\n",
    "    \n",
    "    for col in columns:\n",
    "        data[col] = data[col].str.split('\\t')\n",
    "    return data\n",
    "\n",
    "\n",
    "def columns_to_timestamps(data, columns):\n",
    "    for col in columns:  \n",
    "        data[col] = data[col].apply(lambda x: pd.Timestamp(x, unit='s'))\n",
    "        \n",
    "    return data\n",
    "    \n",
    "cols_to_list = ['text_tokens', 'hashtags', 'present_media', 'present_links', 'present_domains']\n",
    "data = columns_to_list(data, cols_to_list)    \n",
    "\n",
    "cols_to_timestamps = ['tweet_timestamp', 'enaging_user_account_creation', 'reply_timestamp', 'retweet_timestamp', 'retweet_with_comment_timestamp', 'like_timestamp']\n",
    "data = columns_to_timestamps(data, cols_to_timestamps)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(data.shape)\n",
    "display(data.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (k,stats) in res.items():\n",
    "    print(k)\n",
    "    \n",
    "    nvalrows = val_data.shape[0]\n",
    "    reply_mean = stats[\"nreply\"]/stats[\"nrows\"]\n",
    "    retweet_mean = stats[\"nretweet\"]/stats[\"nrows\"]\n",
    "    quote_mean = stats[\"nquote\"]/stats[\"nrows\"]\n",
    "    like_mean = stats[\"nlike\"]/stats[\"nrows\"]\n",
    "    \n",
    "    p = np.full(nvalrows, reply_mean)\n",
    "    gt = val_data.reply\n",
    "    print(\"reply:\", \"rce\", compute_rce(p, gt), \"avgprec\", average_precision_score(gt, p))\n",
    "    p = np.full(nvalrows, retweet_mean)\n",
    "    gt = val_data.retweet\n",
    "    print(\"retweet:\", \"rce\", compute_rce(p, gt), \"avgprec\", average_precision_score(gt, p))\n",
    "    p = np.full(nvalrows, quote_mean)\n",
    "    gt = val_data.quote\n",
    "    print(\"quote:\", \"rce\", compute_rce(p, gt), \"avgprec\", average_precision_score(gt, p))\n",
    "    p = np.full(nvalrows, like_mean)\n",
    "    gt = val_data.like\n",
    "    print(\"like:\", \"rce\", compute_rce(p, gt), \"avgprec\", average_precision_score(gt, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Predicting no engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvalrows = val_data.shape[0]\n",
    "reply_pred = 0.\n",
    "retweet_pred = 0.\n",
    "quote_pred = 0.\n",
    "like_pred = 0.\n",
    "\n",
    "p = np.full(nvalrows, reply_pred)\n",
    "gt = val_data.reply\n",
    "print(\"reply:\", \"rce\", compute_rce(p, gt), \"avgprec\", average_precision_score(gt, p))\n",
    "p = np.full(nvalrows, retweet_pred)\n",
    "gt = val_data.retweet\n",
    "print(\"retweet:\", \"rce\", compute_rce(p, gt), \"avgprec\", average_precision_score(gt, p))\n",
    "p = np.full(nvalrows, quote_pred)\n",
    "gt = val_data.quote\n",
    "print(\"quote:\", \"rce\", compute_rce(p, gt), \"avgprec\", average_precision_score(gt, p))\n",
    "p = np.full(nvalrows, like_pred)\n",
    "gt = val_data.like\n",
    "print(\"like:\", \"rce\", compute_rce(p, gt), \"avgprec\", average_precision_score(gt, p))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Predicting mean engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into train and test\n",
    " Splitting the training set - one hour into train and test data. The training dataset is used for model training and the test dataset for testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_data(path_to_data + dataset_type)\n",
    "\n",
    "# We choose first 5k rows in order to work faster with the data\n",
    "data = data.head(5000)\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size= 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def true_timestamp(t):\n",
    "    return int(not pd.isnull(t))\n",
    "\n",
    "def labels(j):\n",
    "    to_copy = test_data.copy()\n",
    "    to_copy['labed'] = to_copy.apply(lambda row: true_timestamp(row[j]), axis=1)\n",
    "    return to_copy[['tweet_id', 'engaging_user_id', 'labed']]\n",
    "\n",
    "def read_predictions(file):\n",
    "    filename = os.path.basename(file)\n",
    "    #print(filename)     \n",
    "    if (filename.startswith('gt')):\n",
    "        to_sort = pd.read_csv(file, names=['tweet_id', 'engaging_user_id', 'labed'], header=0)\n",
    "        sort = to_sort.sort_values(['tweet_id', 'engaging_user_id', 'labed'])\n",
    "    elif (filename.startswith('pred')):\n",
    "         to_sort = pd.read_csv(file, names=['tweet_id', 'engaging_user_id', 'prediction'], header=0)\n",
    "         sort = to_sort.sort_values(['tweet_id', 'engaging_user_id', 'prediction'])\n",
    "    return sort\n",
    "\n",
    "\n",
    "#ground truth for retweet\n",
    "gt_retweet = labels('retweet_timestamp')\n",
    "gt_retweet.to_csv('gt_retweet.csv')\n",
    "print(read_predictions('gt_retweet.csv')[:10])\n",
    "\n",
    "#ground truth for reply\n",
    "gt_reply = labels('reply_timestamp')\n",
    "gt_reply.to_csv('gt_reply.csv')\n",
    "print(read_predictions('gt_reply.csv')[:10])\n",
    "\n",
    "#ground truth for like\n",
    "gt_like = labels('like_timestamp')\n",
    "gt_like.to_csv('gt_like.csv')\n",
    "print(read_predictions('gt_like.csv')[:10])\n",
    "\n",
    "#ground truth for retweet with comment\n",
    "gt_rc = labels('retweet_with_comment_timestamp')\n",
    "gt_rc.to_csv('gt_rc.csv')\n",
    "print(read_predictions('gt_rc.csv')[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Ratings Matrix\n",
    "### One ratings matrix for each engagement type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a data frame for the unique tweets and a unique one for the engagement between users\n",
    "uTID = data['tweet_id'].unique()\n",
    "uTID.sort()\n",
    "\n",
    "uUID = data['engaging_user_id'].append(data['engaged_with_user_id']).unique()\n",
    "uUID.sort()\n",
    "\n",
    "m = len(uUID)\n",
    "n = len(uTID)\n",
    "\n",
    "#creating internal ids for the users and the tweets\n",
    "userId_to_userIDX = dict(zip(uUID, range(m)))\n",
    "userIDX_to_userId = dict(zip(range(m), uUID))\n",
    "\n",
    "tweetId_to_tweetIDX = dict(zip(uTID, range(n)))\n",
    "tweetIDX_to_tweetId = dict(zip(range(n), uTID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe for the upcoming implementation of the ratings matrix \n",
    "j = ['tweet_id', 'engaging_user_id', 'reply_timestamp', 'retweet_timestamp',\n",
    "       'retweet_with_comment_timestamp', 'like_timestamp']\n",
    "\n",
    "ratings = pd.concat([data['engaging_user_id'].map(userId_to_userIDX),\n",
    "                  data['tweet_id'].map(tweetId_to_tweetIDX),\n",
    "                  data['reply_timestamp'].notnull(),\n",
    "                  data['retweet_timestamp'].notnull(),\n",
    "                  data['retweet_with_comment_timestamp'].notnull(),\n",
    "                  data['like_timestamp'].notnull()], axis = 1)\n",
    "\n",
    "ratings.columns = ['user', 'tweet', 'reply', 'retweet', 'retweet_with_comment', 'like']\n",
    "ratings.sort_values(['user', 'tweet'], inplace = True)\n",
    "\n",
    "ratings.head(n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp\n",
    "\n",
    "#creating the ratings matrices\n",
    "\n",
    "RM_reply = sp.csr_matrix((ratings.reply[ratings.reply], (ratings.user[ratings.reply], ratings.tweet[ratings.reply])), \n",
    "            shape=(m, n))\n",
    "\n",
    "RM_retweet = sp.csr_matrix((ratings.retweet[ratings.retweet], (ratings.user[ratings.retweet], ratings.tweet[ratings.retweet])), \n",
    "            shape=(m, n))\n",
    "\n",
    "RM_retweet_wc = sp.csr_matrix((ratings.retweet_with_comment[ratings.retweet_with_comment], (ratings.user[ratings.retweet_with_comment]             , ratings.tweet[ratings.retweet_with_comment])), shape=(m, n))\n",
    "\n",
    "RM_like = sp.csr_matrix((ratings.like[ratings.like], (ratings.user[ratings.like], ratings.tweet[ratings.like])), \n",
    "            shape=(m, n))\n",
    "\n",
    "display(RM_reply.shape, RM_reply.count_nonzero())\n",
    "display(RM_retweet.shape, RM_retweet.count_nonzero())\n",
    "display(RM_retweet_wc.shape, RM_retweet_wc.count_nonzero())\n",
    "display(RM_like.shape, RM_like.count_nonzero())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-User Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import norm\n",
    "\n",
    "def compute_pairwise_user_similarity(u_id, v_id, RM_type):\n",
    "    u = RM_type[u_id,:].copy()\n",
    "    v = RM_type[v_id,:].copy()\n",
    "    \n",
    "    #cosine similarity formula from the slides based on the vector operations defined above\n",
    "    numerator = u.dot(v.T).A.item()\n",
    "    denominator = norm(u)*norm(v)\n",
    "    \n",
    "    if denominator == 0:\n",
    "        similarity = 0.;\n",
    "    else: \n",
    "        similarity = numerator/denominator\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the function above\n",
    "display(compute_pairwise_user_similarity(15, 5256, RM_reply))\n",
    "display(compute_pairwise_user_similarity(5256, 1642, RM_retweet))\n",
    "display(compute_pairwise_user_similarity(1642, 5422, RM_retweet_wc))\n",
    "display(compute_pairwise_user_similarity(5422, 15, RM_like))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User to all Users Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_user_similarities(u_id, RM_type):\n",
    "    uU = np.empty((m,))\n",
    "\n",
    "    #computing similarities of user u_id with all of the other users\n",
    "    for v_id in range(m):\n",
    "        uU[v_id] = compute_pairwise_user_similarity(u_id, v_id, RM_type)\n",
    "    \n",
    "    return uU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "uU = compute_user_similarities(15, RM_reply)\n",
    "display(uU[1])\n",
    "\n",
    "uU = compute_user_similarities(5256, RM_retweet)\n",
    "display(uU[50])\n",
    "\n",
    "uU = compute_user_similarities(1642, RM_retweet_wc)\n",
    "display(uU[10])\n",
    "\n",
    "uU = compute_user_similarities(5422, RM_like)\n",
    "display(uU[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  User Neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming from sparse matrix to dictionary of keys for easier handling\n",
    "RM_reply_dok = RM_reply.todok()\n",
    "RM_retweet_dok = RM_retweet.todok()\n",
    "RM_retweet_wc_dok = RM_retweet_wc.todok()\n",
    "RM_like_dok = RM_like.todok()\n",
    "\n",
    "k = 10\n",
    "\n",
    "def create_user_neighborhood(u_id, i_id, RM_type, RM_type_dok):\n",
    "    nh = {} ## the neighborhood dict with (user id: similarity) entries\n",
    "    ## nh should not contain u_id and only include users that have rated i_id; there should be at most k neighbors\n",
    "    uU = compute_user_similarities(u_id, RM_type)\n",
    "    uU_copy = uU.copy() ## so that we can modify it, but also keep the original\n",
    "    \n",
    "    sorted_values = np.argsort(uU_copy)[::-1]    \n",
    "        \n",
    "   #counter for k neighbours\n",
    "    ik = 0 \n",
    "    for i in sorted_values:\n",
    "        # checking if i gave a rating to item i_id and making sure i is different from itself\n",
    "        if (i, i_id) in RM_type_dok and i!=u_id:\n",
    "            nh[i] = uU_copy[i]\n",
    "            ik+=1\n",
    "        if ik == k:\n",
    "            break\n",
    "\n",
    "    return nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test neighborhood\n",
    "\n",
    "nh = create_user_neighborhood(15, 595, RM_reply, RM_reply_dok)\n",
    "display(nh)\n",
    "\n",
    "nh = create_user_neighborhood(5256, 437, RM_retweet, RM_retweet_dok)\n",
    "display(nh)\n",
    "\n",
    "nh = create_user_neighborhood(1642, 27, RM_retweet_wc, RM_retweet_wc_dok)\n",
    "display(nh)\n",
    "\n",
    "nh = create_user_neighborhood(5422, 609, RM_like, RM_like_dok)\n",
    "display(nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_internal_ids(u_id, i_id, RM_type, RM_type_dok):\n",
    "\n",
    "    if (u_id, i_id) in RM_type_dok:\n",
    "        print(\"user\", u_id, \"has engaged with item\", i_id, \"with\", RM_type[u_id, i_id])\n",
    "    else:\n",
    "        print(\"user\", u_id, \"has not engaged with item\", i_id)\n",
    "        print(\"k:\", k)\n",
    "\n",
    "\n",
    "    nh = create_user_neighborhood(u_id, i_id, RM_type, RM_type_dok)\n",
    "\n",
    "    neighborhood_weighted_avg = 0.\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "\n",
    "    for v in nh.items():\n",
    "        numerator += nh[v] * RM_type[v,i_id]\n",
    "\n",
    "        denominator += np.absolute(nh[v])\n",
    "\n",
    "\n",
    "    if denominator == 0:\n",
    "        neighborhood_weighted_avg = 0.;\n",
    "    else:\n",
    "        neighborhood_weighted_avg = numerator/denominator\n",
    "\n",
    "\n",
    "    prediction = neighborhood_weighted_avg\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "predict_internal_ids(15, 595, RM_reply, RM_reply_dok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_external_ids(tweet_id, engaging_user_id, RM_type, RM_type_dok):\n",
    "    print(\"user\", engaging_user_id, \"has internal id \", userId_to_userIDX[engaging_user_id])\n",
    "    print(\"tweet\", tweet_id, \"has internal id \", tweetId_to_tweetIDX[tweet_id])\n",
    "    return predict_internal_ids(userId_to_userIDX[engaging_user_id],tweetId_to_tweetIDX[tweet_id], RM_type, RM_type_dok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing different external ids \n",
    "\n",
    "print(\"Reply\")\n",
    "predict_external_ids(\"DCEF6C06DDE77C2DBE7F0BE99B95120A\", \"2284A3F835F7156B2F432B82D8963D27\", RM_reply, RM_reply_dok)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Retweet\")\n",
    "predict_external_ids(\"A3B8BEF795136AAA9E25B5173E80A73D\", \"EBBE15EB3C30A275BF87E7B9A676D12F\", RM_retweet, RM_retweet_dok)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Retweet with Comment\")\n",
    "predict_external_ids(\"089FE87D98654DA3323FE87552B86965\", \"48918F9BDF36C80185112EF228F1429F\", RM_retweet_wc, RM_retweet_wc_dok)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Like\")\n",
    "predict_external_ids(\"DE1604F4816F6B8BD85A9478AE9D32E9\", \"F343F23E25FF1D7041E31E0CF4D026AD\", RM_like, RM_like_dok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Item Collaborative Filtering\n",
    "#### Author: Markus Böck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "iicf = IICF(path_to_data, \"one_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "\n",
    "def evaluate_test_set(path_to_data, dataset_type):\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "        \n",
    "    i = 0\n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "                linereader = csv.reader(f, delimiter='\\x01')\n",
    "                last_timestamp = None\n",
    "                for row in linereader:\n",
    "                    i += 1\n",
    "                    tweet_id, user_id, features, follow, tweet_timestamp = iicf.parse_input_features(row) \n",
    "\n",
    "                    reply_pred, retweet_pred, quote_pred, fav_pred = iicf.predict(tweet_id, user_id, features, follow)\n",
    "                    \n",
    "                    # print(str(tweet_timestamp))\n",
    "                    # print(str(reply_pred)+\" \"+str(retweet_pred)+\" \"+str(quote_pred)+\" \"+str(fav_pred))\n",
    "                    \n",
    "                    output.write(f'{tweet_id},{user_id},{reply_pred},{retweet_pred},{quote_pred},{fav_pred}\\n')\n",
    "                    \n",
    "                    if i % 1000 == 0:\n",
    "                        print(f\"Predicted {i} rows.\", end=\"\\r\")\n",
    "\n",
    "    print(f\"Predicted {i} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluate_test_set(val_path_to_data, val_dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "    positive = len([x for x in gt if x == 1])\n",
    "\n",
    "    ctr = positive/float(len(gt))\n",
    "\n",
    "    return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_expanded_path = os.path.expanduser(val_path_to_data)\n",
    "val_part_files = [os.path.join(val_expanded_path, f) for f in os.listdir(val_expanded_path) if val_dataset_type in f]\n",
    "val_part_files = sorted(val_part_files, key = lambda x:x[-5:])\n",
    "val_part_files\n",
    "val_data = pd.read_csv(val_part_files[0], delimiter='\\x01', header=None, usecols=[2, 14, 20,21,22,23])\n",
    "val_data.columns = [\"tweet_id\", \"engaging_user_id\", 'reply', 'retweet', 'quote', 'like']\n",
    "\n",
    "val_data.reply = (~val_data.reply.isna()).astype(\"int\")\n",
    "val_data.retweet = (~val_data.retweet.isna()).astype(\"int\")\n",
    "val_data.quote = (~val_data.quote.isna()).astype(\"int\")\n",
    "val_data.like = (~val_data.like.isna()).astype(\"int\")\n",
    "\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"results.csv\", header=None)\n",
    "results.columns = [\"tweet_id\", \"user_id\", \"reply\", \"retweet\", \"quote\", \"like\"]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reply scores:\")\n",
    "compute_rce(results.reply, val_data.reply), average_precision_score(val_data.reply, results.reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Retweet scores:\")\n",
    "compute_rce(results.retweet, val_data.retweet), average_precision_score(val_data.retweet, results.retweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quote scores:\")\n",
    "compute_rce(results.quote, val_data.quote), average_precision_score(val_data.quote, results.quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Like scores:\")\n",
    "compute_rce(results.like, val_data.like), average_precision_score(val_data.like, results.like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del iicf # free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "    positive = len([x for x in gt if x == 1])\n",
    "\n",
    "    ctr = positive/float(len(gt))\n",
    "\n",
    "    return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_predictions_fairness(path):\n",
    "    pred = pd.read_csv(path, header=None, names=['tweet_id', 'user_id', 'reply', 'retweet', 'quote', 'like'])\n",
    "    return pred\n",
    "\n",
    "\n",
    "def read_predictions(path, col):\n",
    "    pred_col = {\"reply\": 2, \"retweet\": 3, \"quote\": 4, \"like\": 5}[col]\n",
    "    pred = pd.read_csv(path, header=None, usecols=[0, 1, pred_col], names=['tweet_id', 'user_id', 'reply', 'retweet', 'quote', 'like'])\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(row):\n",
    "    tweet_id = row[all_features_to_idx['tweet_id']]\n",
    "    user_id = row[all_features_to_idx['engaging_user_id']]\n",
    "    \n",
    "#     input_feats = np.zeros((tweet_features.shape[1],),dtype=np.float32)\n",
    "    \n",
    "    follower_count= int(row[all_features_to_idx[\"engaged_with_user_follower_count\"]])\n",
    "    following_count = int(row[all_features_to_idx[\"engaged_with_user_following_count\"]])\n",
    "    verified = bool(row[all_features_to_idx[\"engaged_with_user_is_verified\"]])\n",
    "    \n",
    "    return tweet_id, user_id, follower_count, following_count, verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_data(path, dataset_type):\n",
    "    expanded_path = os.path.expanduser(path)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "    \n",
    "    tweet_groups = pd.DataFrame(columns=['tweet_id', 'user_id', 'follower_count', 'following_count', 'verified'])\n",
    "    \n",
    "    for file in part_files:\n",
    "        with open(file, 'r') as f:\n",
    "            tweet_ids = get_tweet_ids(file)\n",
    "            user_ids = get_user_ids(file)\n",
    "            linereader = csv.reader(f, delimiter='\\x01')\n",
    "            last_timestamp = None\n",
    "            for i, row in enumerate(linereader):\n",
    "                tweet_id, user_id, follower_count, following_count, verified = parse_line(row) \n",
    "                tweet_id_int = tweet_ids[tweet_id]\n",
    "                user_id_int = user_ids[user_id]\n",
    "                dic = {'tweet_id':tweet_id_int, 'user_id':user_id_int,\\\n",
    "                       'follower_count':follower_count, 'following_count':following_count, 'verified':verified}\n",
    "                tweet_groups = tweet_groups.append(dic, ignore_index=True)\n",
    "    return tweet_ids, user_ids, tweet_groups\n",
    "\n",
    "\n",
    "tweet_ids, user_ids, tweet_groups = tweets_data(val_path_to_data, 'one_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_followers(df):\n",
    "    data = df.copy()\n",
    "    data = data.sort_values(by='follower_count', ascending=False)\n",
    "    data['group'] = np.zeros((len(data)), dtype=np.int32)\n",
    "    \n",
    "    for i in range(0,round(len(data)/5)):\n",
    "        data.loc[i, 'group'] = 0\n",
    "        \n",
    "    for i in range(round(len(data)/5), 2*round(len(data)/5)):\n",
    "        data.loc[i, 'group'] = 1\n",
    "        \n",
    "    for i in range(2*round(len(data)/5), 3*round(len(data)/5)):\n",
    "        data.loc[i, 'group'] = 2\n",
    "        \n",
    "    for i in range(3*round(len(data)/5), 4*round(len(data)/5)):\n",
    "        data.loc[i, 'group'] = 3\n",
    "        \n",
    "    for i in range(4*round(len(data)/5), len(data)):\n",
    "        data.loc[i, 'group'] = 4\n",
    "    \n",
    "    return data\n",
    "\n",
    "groups = group_by_followers(tweet_groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "\n",
    "\n",
    "ground_truth = read_predictions(\"gt.csv\", 'reply') # will return data in the form (tweet_id, user_id, labed (1 or 0))\n",
    "predictions = read_predictions(\"results.csv\", 'reply') # will return data in the form (tweet_id, user_id, prediction)\n",
    "\n",
    "predictions['tweet_id'] = predictions['tweet_id'].map(tweet_ids)\n",
    "predictions['user_id'] = predictions['user_id'].map(user_ids)\n",
    "ground_truth['tweet_id'] = ground_truth['tweet_id'].map(tweet_ids)\n",
    "ground_truth['user_id'] = ground_truth['user_id'].map(user_ids)\n",
    "\n",
    "predictions = pd.merge(predictions, groups[['user_id', 'group']], how='left', on = 'user_id')\n",
    "ground_truth = pd.merge(ground_truth, groups[['user_id', 'group']], how='left', on = 'user_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting for groups (this is assuming ground_truth is a csv again)\n",
    "# also assuming that predictions has class membership. We should sort this out in the least painful way\n",
    "# predictions has schema (tweet_id, user_id, , group, prediction)\n",
    "\n",
    "col = 'reply'\n",
    "pred_col = {\"reply\": 2, \"retweet\": 3, \"quote\": 4, \"like\": 5}[col]\n",
    "\n",
    "rce = {}\n",
    "average_precision = {}\n",
    "accuracy = {}\n",
    "for i in range(5):\n",
    "    group_predictions = [p[pred_col] for p in predictions.values if p[-1] == i]\n",
    "    group_ground_truth = [p[pred_col] for p in ground_truth.values if p[-1] == i]\n",
    "    rce[i] = compute_rce(group_predictions, group_ground_truth)\n",
    "#     average_precision[i] = average_precision_score(np.array(group_predictions), np.array(group_ground_truth))\n",
    "#     accuracy[i] = np.mean(group_predictions == group_ground_truth)\n",
    "\n",
    "\n",
    "print('The rces for the groups of popularity:')\n",
    "for i in range(5):\n",
    "    print(\"RCE for group {0}:\".format(i), rce[i])\n",
    "#     print(\"average_precision:\", average_precision[i])\n",
    "#     print(\"accuracy:\", accuracy[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zeroR\n",
    "rce: -621.8494688006682  \n",
    "\n",
    "#### item item\n",
    "rce: -233.43933830426766"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by user verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groups = tweet_groups[['tweet_id', 'user_id', 'verified']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = read_predictions(\"gt.csv\", 'reply') # will return data in the form (tweet_id, user_id, labed (1 or 0))\n",
    "predictions = read_predictions(\"results.csv\", 'reply') # will return data in the form (tweet_id, user_id, prediction)\n",
    "\n",
    "predictions['tweet_id'] = predictions['tweet_id'].map(tweet_ids)\n",
    "predictions['user_id'] = predictions['user_id'].map(user_ids)\n",
    "ground_truth['tweet_id'] = ground_truth['tweet_id'].map(tweet_ids)\n",
    "ground_truth['user_id'] = ground_truth['user_id'].map(user_ids)\n",
    "\n",
    "predictions = pd.merge(predictions, groups[['user_id', 'verified']], how='left', on = 'user_id')\n",
    "ground_truth = pd.merge(ground_truth, groups[['user_id', 'verified']], how='left', on = 'user_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting for groups (this is assuming ground_truth is a csv again)\n",
    "# also assuming that predictions has class membership. We should sort this out in the least painful way\n",
    "# predictions has schema (tweet_id, user_id, , group, prediction)\n",
    "\n",
    "col = 'reply'\n",
    "pred_col = {\"reply\": 2, \"retweet\": 3, \"quote\": 4, \"like\": 5}[col]\n",
    "\n",
    "group_predictions_true = [p[pred_col] for p in predictions.values if p[-1] == True]\n",
    "group_ground_truth_true = [p[pred_col] for p in ground_truth.values if p[-1] == True]\n",
    "rce_true = compute_rce(group_predictions, group_ground_truth)\n",
    "\n",
    "\n",
    "group_predictions_false = [p[pred_col] for p in predictions.values if p[-1] == False]\n",
    "group_ground_truth_false = [p[pred_col] for p in ground_truth.values if p[-1] == False]\n",
    "rce_false = compute_rce(group_predictions, group_ground_truth)\n",
    "#     average_precision[i] = average_precision_score(np.array(group_predictions), np.array(group_ground_truth))\n",
    "#     accuracy[i] = np.mean(group_predictions == group_ground_truth)\n",
    "\n",
    "\n",
    "print('The rces for the groups of users with verified accounts vs not verified ones:')\n",
    "print(\"RCE for verified users:\", rce_true)\n",
    "print(\"RCE for non-verified users:\", rce_false)\n",
    "#     print(\"average_precision:\", average_precision[i])\n",
    "#     print(\"accuracy:\", accuracy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf000a0073acaf52bcde389fa20cf1d6",
     "grade": true,
     "grade_id": "cell-d807d29f081e031b",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
